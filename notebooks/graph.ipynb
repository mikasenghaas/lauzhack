{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the multi-modal for intermodal route planning\n",
    "\n",
    "**Nodes**: Stations in the SBB traffic network. Curated from the following\n",
    "sources:\n",
    "\n",
    "- `regional_station.csv` from\n",
    "  [here](https://data.sbb.ch/explore/dataset/regionale-fahrplane/information/)\n",
    "\n",
    "- `city_station.csv` from\n",
    "  [here](https://data.sbb.ch/explore/dataset/stadtefahrplan/information/)\n",
    "\n",
    "- `pr_station.csv` from\n",
    "  [here](https://data.sbb.ch/explore/dataset/mobilitat/information/)\n",
    "\n",
    "Each node has the `station_name` as the primary attribute and then also\n",
    "information about the location of the station (`pos` (tuple of lon, lat float),\n",
    "`loc` (string repr of the former), `opucid` (an identifier) and `abbr` (the\n",
    "abbreviation of the station name)).\n",
    "\n",
    "**Edges**: Trip segments between stations for multiple modalities (foot, bike,\n",
    "car, train). The latter sourced from the timetable of the SBB for a given day\n",
    "(see `timetable.ipynb` for details). The former are generated from the `nodes`\n",
    "by computing all pairs of nodes that are within a given time travel threshold\n",
    "(e.g. all stations within 30 minutes foot distance).\n",
    "\n",
    "Three types of nodes:\n",
    "\n",
    "- Static for modalities `foot`, `bike` and `car` from each node given a time\n",
    "  threshold\n",
    "- Dynamic given start position for all modalities given with k-nearest neighbors\n",
    "- ...\n",
    "\n",
    "Results: Directed, multi-edged graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Immports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journey_id</th>\n",
       "      <th>arrival</th>\n",
       "      <th>departure</th>\n",
       "      <th>station</th>\n",
       "      <th>opuic</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:1094:001</td>\n",
       "      <td>2023-12-02 00:06:00</td>\n",
       "      <td>2023-12-02 00:07:00</td>\n",
       "      <td>Thun</td>\n",
       "      <td>8507100</td>\n",
       "      <td>46.75485273059273, 7.6296058286694795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:1096:001</td>\n",
       "      <td>2023-12-02 00:37:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Basel SBB</td>\n",
       "      <td>8500010</td>\n",
       "      <td>47.5474120550501, 7.589562790156525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:1251:001</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-01 06:06:00</td>\n",
       "      <td>Basel SBB</td>\n",
       "      <td>8500010</td>\n",
       "      <td>47.5474120550501, 7.589562790156525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:1258:001</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-01 20:08:00</td>\n",
       "      <td>Chur</td>\n",
       "      <td>8509000</td>\n",
       "      <td>46.853084162764006, 9.52893773304132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:1411:001</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-01 07:10:00</td>\n",
       "      <td>Bern</td>\n",
       "      <td>8507000</td>\n",
       "      <td>46.948832290498416, 7.439130889923935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       journey_id             arrival           departure    station    opuic  \\\n",
       "0  85:11:1094:001 2023-12-02 00:06:00 2023-12-02 00:07:00       Thun  8507100   \n",
       "1  85:11:1096:001 2023-12-02 00:37:00                 NaT  Basel SBB  8500010   \n",
       "2  85:11:1251:001                 NaT 2023-12-01 06:06:00  Basel SBB  8500010   \n",
       "3  85:11:1258:001                 NaT 2023-12-01 20:08:00       Chur  8509000   \n",
       "4  85:11:1411:001                 NaT 2023-12-01 07:10:00       Bern  8507000   \n",
       "\n",
       "                                     pos  \n",
       "0  46.75485273059273, 7.6296058286694795  \n",
       "1    47.5474120550501, 7.589562790156525  \n",
       "2    47.5474120550501, 7.589562790156525  \n",
       "3   46.853084162764006, 9.52893773304132  \n",
       "4  46.948832290498416, 7.439130889923935  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../data/ist-daten-sbb.csv\", sep=\";\")\n",
    "\n",
    "# Select and rename columns\n",
    "cols = {\n",
    "    \"Journey identifier\": \"journey_id\",\n",
    "    \"Arrival time\": \"arrival\",\n",
    "    \"Departure time\": \"departure\",\n",
    "    \"Stop name\": \"station\",\n",
    "    \"OPUIC\": \"opuic\",\n",
    "    \"Geopos\": \"pos\",\n",
    "}\n",
    "\n",
    "# Select and rename columns\n",
    "df = df[cols.keys()].rename(columns=cols)\n",
    "\n",
    "# Convert time columns to datetime\n",
    "df[\"arrival\"] = pd.to_datetime(df[\"arrival\"])\n",
    "df[\"departure\"] = pd.to_datetime(df[\"departure\"])\n",
    "\n",
    "# Show the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Route Network from SBB Timetable\n",
    "\n",
    "Using data from `01.12.2023`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5726/5726 [00:26<00:00, 220.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build edge list (with edge attributes) for train journeys\n",
    "edges = []\n",
    "for journey_id in tqdm(df.journey_id.unique()):\n",
    "    trip = df[df.journey_id == journey_id].sort_values(\"departure\", inplace=False)\n",
    "    trip_name = f\"{trip.iloc[0].station} -> {trip.iloc[-1].station}\"\n",
    "\n",
    "    for i in range(len(trip) - 1):\n",
    "        edges.append(\n",
    "            (\n",
    "                trip.iloc[i].station,\n",
    "                trip.iloc[i + 1].station,\n",
    "                {\n",
    "                    \"departure\": trip.iloc[i].departure,\n",
    "                    \"arrival\": trip.iloc[i + 1].arrival,\n",
    "                    \"duration\": trip.iloc[i + 1].arrival - trip.iloc[i].departure,\n",
    "                    \"journey_id\": journey_id,\n",
    "                    \"trip_name\": trip_name,\n",
    "                    \"type\": \"train\",\n",
    "                },\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Interlaken Ost',\n",
       " 'Interlaken West',\n",
       " {'departure': Timestamp('2023-12-01 23:33:00'),\n",
       "  'arrival': Timestamp('2023-12-01 23:36:00'),\n",
       "  'duration': Timedelta('0 days 00:03:00'),\n",
       "  'journey_id': '85:11:1094:001',\n",
       "  'trip_name': 'Interlaken Ost -> Bern',\n",
       "  'type': 'train'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise multi-graph object\n",
    "G = nx.MultiDiGraph(edges)\n",
    "\n",
    "# We have the following attributes for each edge (for train journeys)\n",
    "list(G.edges(data=True))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add node attributes (station id and position)\n",
    "unique_stations = df.drop_duplicates(subset=[\"station\"])\n",
    "node_attrs = {\n",
    "    row.station: {\"opuic\": row.opuic, \"pos\": row.pos}\n",
    "    for _, row in unique_stations.iterrows()\n",
    "}\n",
    "\n",
    "nx.set_node_attributes(G, node_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add information about whether station has parking spot (`has_pr`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 409 of 523 PR stations. 114 not found.\n"
     ]
    }
   ],
   "source": [
    "# Read in city and regional stations\n",
    "pr_stations = pd.read_csv(\"../data/pr_stations.csv\")\n",
    "\n",
    "# Rename columns\n",
    "pr_stations = pr_stations.rename(columns={\"station\": \"name\", \"station_abbr\": \"abbr\"})\n",
    "\n",
    "# Initialise has_pr to False for all nodes\n",
    "for node in G.nodes:\n",
    "    G.nodes[node][\"has_pr\"] = False\n",
    "\n",
    "not_found = 0\n",
    "for pr_station in pr_stations.name.unique():\n",
    "    if pr_station in G.nodes:\n",
    "        G.nodes[pr_station][\"has_pr\"] = True\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(\n",
    "    f\"Added {pr_stations.name.nunique() - not_found} of {pr_stations.name.nunique()} PR stations. {not_found} not found.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Interlaken Ost',\n",
       " {'opuic': 8507492,\n",
       "  'pos': '46.690499996187924, 7.869000004346448',\n",
       "  'has_pr': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have the following attributes for each node\n",
    "list(G.nodes(data=True))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pino-Tronzano', 'Maccagno', 'Colmegna', 'Lottstetten', 'Jestetten']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have position for all stations\n",
    "[node for node, attr in G.nodes(data=True) if attr[\"pos\"] is np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grow network to include other modalities\n",
    "\n",
    "We now include the following modalities: `foot`, `bike`, `car`, `train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/603 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/603 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'route'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonas-mika/hack/notebooks/graph.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Otherwise compute travel time for mode and add edge if below threshold\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m time \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mget_exact_travel_time(u_pos, v_pos, mode)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m time \u001b[39m<\u001b[39m limits[mode]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# print(f\"Adding from {u} to {v} via {mode} in {(time/60):.2f}min (less than {limits[mode]/60:.2f}min)\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas-mika/hack/notebooks/graph.ipynb#Y145sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     G\u001b[39m.\u001b[39madd_edge(u, v, mode\u001b[39m=\u001b[39mmode, duration\u001b[39m=\u001b[39mdatetime\u001b[39m.\u001b[39mtimedelta(seconds\u001b[39m=\u001b[39mtime))\n",
      "File \u001b[0;32m~/hack/notebooks/../utils.py:164\u001b[0m, in \u001b[0;36mget_exact_travel_time\u001b[0;34m(start, end, method)\u001b[0m\n\u001b[1;32m    162\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(endpoint, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    163\u001b[0m data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[0;32m--> 164\u001b[0m seconds \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39;49m\u001b[39mroute\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m seconds\n",
      "\u001b[0;31mKeyError\u001b[0m: 'route'"
     ]
    }
   ],
   "source": [
    "# Utility to grow a graph from a list of nodes\n",
    "\n",
    "# Set limits km/h\n",
    "avg_speed = {\n",
    "    \"foot\": 1,  # m/s\n",
    "    \"bike\": 2,  # m/s\n",
    "    \"car\": 10,  # m/s\n",
    "}\n",
    "\n",
    "limits = {\n",
    "    \"foot\": 900,  # s (30min)\n",
    "    \"bike\": 900,  # s (1h)\n",
    "    \"car\": 900,  # s (1h)\n",
    "}\n",
    "\n",
    "# Iterate over all pairs of nodes and mode types (V*V*num_modes)\n",
    "added_edges = {\n",
    "    \"foot\": 0,\n",
    "    \"bike\": 0,\n",
    "    \"car\": 0,\n",
    "}\n",
    "for u, attr_u in tqdm(G.nodes(data=True)):\n",
    "    for v, attr_v in G.nodes(data=True):\n",
    "        # Discard if same node\n",
    "        if u == v:\n",
    "            continue\n",
    "\n",
    "        # Get longitude and latitude for start and end station\n",
    "        u_pos = attr_u[\"pos\"]\n",
    "        v_pos = attr_v[\"pos\"]\n",
    "\n",
    "        # Discard if no position available\n",
    "        if u_pos is np.nan or v_pos is np.nan:\n",
    "            continue\n",
    "\n",
    "        for mode in [\"foot\", \"bike\", \"car\"]:\n",
    "            # Discard if air distance is above thresholds (not reachable with mode)\n",
    "            dist = utils.get_distance(u_pos, v_pos)  # dist in m\n",
    "            if dist > limits[mode] * avg_speed[mode]:\n",
    "                continue\n",
    "\n",
    "            # Otherwise compute travel time for mode and add edge if below threshold\n",
    "            time = utils.get_exact_travel_time(u_pos, v_pos, mode)\n",
    "            if time < limits[mode]:\n",
    "                # print(f\"Adding from {u} to {v} via {mode} in {(time/60):.2f}min (less than {limits[mode]/60:.2f}min)\")\n",
    "                G.add_edge(u, v, mode=mode,\n",
    "                           duration=datetime.timedelta(seconds=time))\n",
    "                added_edges[mode] += 1\n",
    "\n",
    "print(f\"Added {added_edges['foot']} foot edges.\")\n",
    "print(f\"Added {added_edges['bike']} bike edges.\")\n",
    "print(f\"Added {added_edges['car']} car edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the map projection and the transformation\n",
    "proj = ccrs.Mercator()\n",
    "transform = ccrs.Geodetic()\n",
    "\n",
    "# Create a figure with an axes set with the projection\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": proj}, figsize=(30, 10))\n",
    "\n",
    "# Set the extent of the map (min longitude, max longitude, min latitude, max latitude)\n",
    "ax.set_extent([5, 12, 45.5, 48], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n",
    "\n",
    "# Draw nodes (use scatter for individual node plotting)\n",
    "for _, attr in G.nodes(data=True):\n",
    "    lon, lat = attr[\"pos\"]\n",
    "    col = \"red\" if attr[\"has_pr\"] else \"blue\"\n",
    "    ax.scatter(lat, lon, s=10, color=col, transform=transform, zorder=3)\n",
    "\n",
    "# Draw edges (use scatter for individual edge plotting)\n",
    "# for edge in G.edges():\n",
    "#    lons, lats = zip(*[pos[node] for node in edge])\n",
    "#    ax.plot(lons, lats, color='gray', linewidth=2, transform=transform, zorder=2)\n",
    "\n",
    "# Add node labels\n",
    "# for node, (lon, lat) in pos.items():\n",
    "#   plt.text(lon-0.02, lat-0.015, node, transform=transform, horizontalalignment='right')\n",
    "\n",
    "\n",
    "print(\"All city and regional stations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/graph.pickle\", \"wb\") as file:\n",
    "    pickle.dump(G, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauzhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
